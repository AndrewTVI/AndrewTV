name: Update latest social posts

on:
  schedule:
    - cron: '*/30 * * * *'      # cada 30 minutos
  workflow_dispatch: {}          # ejecutable manualmente

permissions:
  contents: write                # necesario para poder commitear

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: 'Fetch latest TikTok & Tweet (robusto - RSS -> snscrape, solo propios)'
        shell: bash
        run: |
          # No usamos -e para que 422/500 no rompan el job
          set -uo pipefail
          mkdir -p data

          USER_RX='iAndres_Soto'   # tu @ en X/Twitter (ojo con mayúsculas/minúsculas en la URL final)
          USER_LOWER="$(echo "$USER_RX" | tr '[:upper:]' '[:lower:]')"  # para búsquedas si hiciera falta

          sudo apt-get update -y >/dev/null
          sudo apt-get install -y jq curl python3-pip >/dev/null
          python3 -m pip install --upgrade pip >/dev/null
          python3 -m pip install snscrape >/dev/null

          # Descarga JSON con reintentos; si falla, devuelve {}
          json_get () {
            local url="$1"
            curl -sSL --retry 2 --retry-delay 1 --fail "$url" 2>/dev/null || printf '{}'
          }

          ####### TIKTOK #######
          # 1) RSS preferido
          TT_JSON="$(json_get 'https://api.rss2json.com/v1/api.json?rss_url=https%3A%2F%2Frsshub.app%2Ftiktok%2Fuser%2Fandrewtvi')"
          TIKTOK="$(echo "$TT_JSON" | jq -r '
            if (.items|type=="array" and (.items|length)>0 and (.items[0].link|type=="string"))
              then .items[0].link else empty end
          ' 2>/dev/null || printf '')"

          # 2) Fallback scrape
          if [ -z "$TIKTOK" ]; then
            RAW_TT="$(curl -sSL 'https://r.jina.ai/http://www.tiktok.com/@andrewtvi' 2>/dev/null || true)"
            TIKTOK="$(printf '%s' "$RAW_TT" \
              | grep -oEi 'https://www\.tiktok\.com/@andrewtvi/video/[0-9]+' \
              | head -n1 || true)"
          fi

          ####### TWITTER/X (solo tus tweets) con snscrape #######
          # Filtra "from:USER exclude:retweets exclude:replies" y toma el más reciente
          TWEET_ID="$(snscrape --jsonl --max-results 1 "from:${USER_RX} exclude:retweets exclude:replies" \
                      | jq -r '.id' | head -n1 2>/dev/null || true)"

          if [ -n "${TWEET_ID:-}" ]; then
            TWEET="https://twitter.com/${USER_RX}/status/${TWEET_ID}"
          else
            # Fallback scrape (x.com/twitter.com) SOLO del usuario
            RAW_X="$(curl -sSL "https://r.jina.ai/http://x.com/${USER_RX}" 2>/dev/null || true)"
            RAW_TW="$(curl -sSL "https://r.jina.ai/http://twitter.com/${USER_RX}" 2>/dev/null || true)"
            RAW_ALL="$(printf '%s\n%s' "$RAW_X" "$RAW_TW")"

            ALL_SELF="$(printf '%s' "$RAW_ALL" \
              | grep -oEi "https?://(x\.com|twitter\.com)/${USER_RX}/status/[0-9]+" \
              | sed -E 's#^https?://x\.com/#https://twitter.com/#I' \
              | sort -u)"

            # El primero que aparezca (normalmente el más arriba en la página)
            TWEET="$(echo "$ALL_SELF" | sed -n '1p' || true)"
          fi

          echo "TIKTOK: ${TIKTOK:-<vacío>}"
          echo "TWEET : ${TWEET:-<vacío>}"

          # Genera JSON sí o sí (aunque alguno venga vacío)
          TIKTOK_SAFE=${TIKTOK//\"/\\\"}
          TWEET_SAFE=${TWEET//\"/\\\"}
          printf '{ "tiktok": "%s", "tweet": "%s" }\n' "$TIKTOK_SAFE" "$TWEET_SAFE" > data/latest.json

          echo "latest.json:"
          cat data/latest.json

      - name: Commit & push if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update latest.json"
          file_pattern: data/latest.json
